{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1)Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
        "multiprocessing is a better choice?"
      ],
      "metadata": {
        "id": "QhtDSy6Y-TnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A better understanding of when one should be multithreaded is this-the kind of task that is going to be I/O-bound, usually waiting for I/O to occur, such as reading a file, web request, or database query. Multithreading is more effective in these circumstances because multithreadedly independent processes can perform other tasks concurrently.\n",
        "Shared Memory: When tasks need to share data, for instance, they may share variables during their working duration, making multithreading easier because they run in the same memory space.\n",
        "Less Memory Overhead: Threads, with their light weight compared to processes, take up less memory. It allows multithreading to be advantageous when lightweight, fast processes are required.\n",
        "Ease of Context Switching: In raising and managing tasks, switching among threads tends to take lower overhead than switching between processes.\n",
        "Other beneficial qualities of multiprocessing include:\n",
        "-These constitute CPU-bound tasks that stretch the boundaries of intensive computing with mathematical calculations, data processing, or video rendering. Multiprocessing utilizes the multi-core functionality of the CPU in obtaining true parallelism.\n",
        "-Process Isolation: It is confirmed that few processes maintain the uniqueness of control by ensuring an independent memory space for those processes.\n",
        "Stability and Safety: A task crash will only affect that task and not others in multiprocessing, thus makes it better for tasks which demand stability and fault isolation.\n",
        "Maximizing Use of Multi-core Systems: Multiprocessing serves the purpose of using multi-core systems thereby speeding up the operation of parallel CPU-intensive tasks.\n"
      ],
      "metadata": {
        "id": "qUpxcCgk_FZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
        "A pool of processes may be defined as the unit by which an upper management team designs related tasks to execute concurrently in a distributed or parallel realization. The processes are held in a pattern which is already employed in multi-processing or parallel computing to manage and distribute the work over multiple processes while controlling the excess overhead in constantly invoking new processes?\n",
        "\n"
      ],
      "metadata": {
        "id": "pysbeR3A_bJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Concepts:\n",
        "Pre-instantiated Processes: In process pools, a set number of processes are instantiated in advance specifically so that they may get inactive or idle till assigned a task. By that the business of constantly spawning processes for each task-a rather tantrum overwhelmed commercial product-conjectures are avoided.\n",
        "\n",
        "Task Queue: The tasks which are to be executed are generally placed in a queue, and the worker processes in the pool retrieve their tasks from the execution-ready queue. This decoupling of task scheduling and execution from process management adds to the scalability of the system.\n",
        "\n",
        "Worker Pool: The pool consists of a defined number of worker processes that can run simultaneously, unlike in the standard approach of creating worker processes. When a particular worker process finishes executing a job, it picks the next task from the queue.\n",
        "\n",
        "Task Distribution: Tasks will be handed out to workers in a complex scheme to the best efficiency. A round-robin technique or other scheduling mechanisms, depending on the implementation, can be applied."
      ],
      "metadata": {
        "id": "mdbU0EIjWPTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)Explain what multiprocessing is and why it is used in Python programs.\n",
        "Python multiprocessing is a process whereby several processes can execute simultaneously with the use of multiple CPU cores, which, in turn, enables running tasks in parallel. This makes Python programs run more efficiently. For CPU-bound tasks where several tasks can be executed simultaneously without interfering with one another, this module of multiprocessing enables such execution in Python. Multiprocessing is, thus, one of the most important performance-enhancing techniques for applications needing to perform a huge number of independent or parallel tasks.\n"
      ],
      "metadata": {
        "id": "HWb_qg2XWWYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is multiprocessing used in Python?\n",
        "GIL at Python:\n",
        "By default, CPython uses the so-called Global Interpreter Lock-a mutex (lock) that ensures only one thread can execute Python bytecode at any instant inside a single process. That means even though Python does support threading-essentially, multi-threading-they can't utilize multiple CPU cores really well in CPU-bound operations due to this GIL that will allow only one thread to execute Python code at a time.\n",
        "\n",
        "One of the ways this problem is resolved is by the creation of separate processes for each task through multiprocessing, each with its memory space and GIL. That way, Python can utilize more than one CPU core; hence, true parallelism in CPU-bound jobs is assured.\n",
        "\n",
        "Parallelism for CPU-bound Tasks:\n",
        "In general, for tasks that require high computation-numerical computations, for instance, or some image processing, or even simulations, it is instead multiprocessing that cuts down execution time drastically because of the parallelization of work across different cores. This is because most of the processes can run on different cores to maximize efficiency and speed.\n",
        "\n",
        "Improving Performance for I/O-bound Tasks:\n",
        "Although multiprocessing is especially useful in the case of CPU-bound tasks, it can be useful for I/O-bound tasks also-such as downloading files or database queries-if one needs to handle many tasks concurrently."
      ],
      "metadata": {
        "id": "sDLuU8MLWlb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4)Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
        "thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
        "threading.Lock?"
      ],
      "metadata": {
        "id": "d-KcQGbnW7ns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_JW8FLe9jqw",
        "outputId": "601440fd-9366-4e8a-b4c4-78fef5e6e964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 0 to the list\n",
            "Removed 0 from the list\n",
            "Added 1 to the list\n",
            "Added 2 to the list\n",
            "Removed 1 from the list\n",
            "Added 3 to the list\n",
            "Added 4 to the list\n",
            "Removed 2 from the list\n",
            "Removed 3 from the list\n",
            "Removed 4 from the list\n",
            "Final shared list: []\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared list and a Lock to prevent race conditions\n",
        "shared_list = []\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_to_list():\n",
        "    for i in range(5):\n",
        "        time.sleep(1)  # Simulating work\n",
        "        with list_lock:  # Locking the shared resource to avoid race conditions\n",
        "            shared_list.append(i)\n",
        "            print(f\"Added {i} to the list\")\n",
        "\n",
        "def remove_from_list():\n",
        "    for i in range(5):\n",
        "        time.sleep(2)\n",
        "        with list_lock:\n",
        "            if shared_list:\n",
        "                removed_item = shared_list.pop(0)\n",
        "                print(f\"Removed {removed_item} from the list\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove\")\n",
        "add_thread = threading.Thread(target=add_to_list)\n",
        "remove_thread = threading.Thread(target=remove_from_list)\n",
        "add_thread.start()\n",
        "remove_thread.start()\n",
        "\n",
        "add_thread.join()\n",
        "remove_thread.join()\n",
        "\n",
        "print(\"Final shared list:\", shared_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Describe the methods and tools available in Python for safely sharing data between threads and\n",
        "processes?"
      ],
      "metadata": {
        "id": "Hz2xq38FXjvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. threading.Lock\n",
        "Usage: A basic lock that allows at most one thread execute the same resource at the same time.\n",
        "Example Use Case: Usually used to protect critical sections of code where shared data is being changed.\n",
        "\n",
        "b. threading.RLock (Reentrant Lock)\n",
        "Usage: A kind of lock that supports recursive acquisition by the same thread.\n",
        "Useful in the case when a thread has to acquire the same lock in different parts of a program or recursively within the same function.\n",
        "\n",
        "c. threading.Semaphore\n",
        "The purpose: A semaphore controls the access to a shared resource depending on the availability of that resource. There is a bound on the number of threads that can access the resource simultaneously.\n",
        "\n",
        "d. threading.Condition\n",
        "Purpose: A condition variable allows threads to wait for some condition to be met before proceeding.\n",
        "Usage: Often used in producer-consumer scenarios where threads wait until data becomes available or until a certain state is reached."
      ],
      "metadata": {
        "id": "74HOl9vsXp4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
        "Why Handle Exceptions in Concurrent Programs:"
      ],
      "metadata": {
        "id": "E8nM8A72X6ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fault Isolation: Prevent one thread/process failure from affecting others.\n",
        "Graceful Termination: Avoid abrupt crashes and ensure proper cleanup.\n",
        "Deadlock Prevention: Prevent deadlocks when exceptions occur while holding locks.\n",
        "\n",
        "Error Reporting: Capture detailed error information for debugging.\n",
        "Resource Management: Ensure resources are properly released even after errors.\n",
        "\n",
        "Techniques for Handling Exceptions:\n",
        "1. In Multithreading:\n",
        "Try-Except Block: Wrap thread logic with try-except to handle exceptions locally.\n",
        "ThreadPoolExecutor and Future.result(): Use result() to catch exceptions raised in threads and handle them in the main thread.\n",
        "Logging: Use logging module to log exceptions for better diagnostics.\n",
        "\n",
        "2. In Multiprocessing:\n",
        "Try-Except Block: Handle exceptions inside each process using try-except.\n",
        "multiprocessing.Pool and apply_async(): Use apply_async() with error_callback to capture exceptions.\n",
        "multiprocessing.Manager: Use shared state (e.g., list) to track and communicate exceptions between processes."
      ],
      "metadata": {
        "id": "uDGlk50XYVTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
        "Use concurrent.futures.ThreadPoolExecutor to manage the threads?"
      ],
      "metadata": {
        "id": "KgN89fw0YjGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate the factorial of a number\n",
        "def calculate_factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main function to manage the thread pool and calculate factorials concurrently\n",
        "def main():\n",
        "    # Create a ThreadPoolExecutor with a number of threads equal to the number of tasks (in this case, 10)\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Submit tasks (calculating factorials for numbers 1 to 10)\n",
        "        numbers = range(1, 11)  # Numbers 1 to 10\n",
        "        results = executor.map(calculate_factorial, numbers)\n",
        "\n",
        "        # Print the results\n",
        "        for number, result in zip(numbers, results):\n",
        "            print(f\"Factorial of {number} is {result}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC5l_dhq-MF0",
        "outputId": "b7817cf1-e460-44c1-ee49-dc2c48d96c32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 1 is 1\n",
            "Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
        "parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "processes)?"
      ],
      "metadata": {
        "id": "92u4aqj1Y2iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def compute_square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure the execution time for different pool sizes\n",
        "def measure_time(pool_size):\n",
        "    # Create a Pool with the specified number of processes\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        # Start the timer\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Map the compute_square function to the numbers 1 to 10\n",
        "        results = pool.map(compute_square, range(1, 11))\n",
        "\n",
        "        # Measure the time taken\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "                # Print the results and the time taken\n",
        "        print(f\"Results (Pool size = {pool_size}): {results}\")\n",
        "        print(f\"Time taken with {pool_size} processes: {elapsed_time:.4f} seconds\\n\")\n",
        "\n",
        "# Main function to run the program with different pool sizes\n",
        "def main():\n",
        "    for pool_size in [2, 4, 8]:\n",
        "        measure_time(pool_size)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP8zKFSYZA6q",
        "outputId": "e65ac389-eed4-49e0-e7d7-8b21544f9362"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results (Pool size = 2): [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken with 2 processes: 0.0017 seconds\n",
            "\n",
            "Results (Pool size = 4): [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken with 4 processes: 0.0029 seconds\n",
            "\n",
            "Results (Pool size = 8): [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken with 8 processes: 0.0029 seconds\n",
            "\n"
          ]
        }
      ]
    }
  ]
}